{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code Details\n",
    "Author: Rory Angus<br>\n",
    "Created: 19NOV18<br>\n",
    "Version: 0.1<br>\n",
    "***\n",
    "This code is to test a writing of data to a MongoDB. <br>\n",
    "This is a proof of concept and the data is real. However, it does not bring all of it into Mongo, only the key fields.\n",
    "This uses data that was extracted after the SSO data model was implemented at LE on the platform.\n",
    "The data now is in two parts. The groups and their members as well as the users linked to the results.\n",
    "Please note that the results from doing the survey can be more than two per journey. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Package Importing + Variable Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import datetime\n",
    "\n",
    "# mongo stuff\n",
    "import pymongo\n",
    "from pymongo import MongoClient\n",
    "from bson.objectid import ObjectId\n",
    "import bson\n",
    "\n",
    "# json stuff\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the file to read. This needs to be manually updated\n",
    "readLoc = \"~/datasets/CLARA/190328_052400_LE_LivePlatform_IndividualResults.json\"\n",
    "# if true the code outputs to the notebook a whole of diagnostic data that is helpful when writing but not so much when running it for real\n",
    "verbose = False\n",
    "# first run will truncate the target database and reload it from scratch. Once delta updates have been implmented this needs adjusting\n",
    "first_run = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set display options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# further details found by running:\n",
    "# pd.describe_option('display')\n",
    "# set the values to show all of the columns etc.\n",
    "pd.set_option('display.max_columns', None)  # or 1000\n",
    "pd.set_option('display.max_rows', None)  # or 1000\n",
    "pd.set_option('display.max_colwidth', -1)  # or 199\n",
    "\n",
    "# locals() # show all of the local environments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Connect to Mongo DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the connection to MongoDB\n",
    "# define the location of the Mongo DB Server\n",
    "# in this instance it is a local copy running on the dev machine. This is configurable at this point.\n",
    "client = MongoClient('127.0.0.1', 27017)\n",
    "\n",
    "# define what the database is called.\n",
    "db = client.CLARA\n",
    "\n",
    "# define the collection\n",
    "raw_data_collection = db.raw_data_user_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Command to clean the databzse if needed when running this code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete the raw_data_collection - used for testing\n",
    "if first_run:\n",
    "    raw_data_collection.drop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The web framework gets post_id from the URL and passes it as a string\n",
    "def get(post_id):\n",
    "    # Convert from string to ObjectId:\n",
    "    document = client.db.collection.find_one({'_id': ObjectId(post_id)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Place CLARA Results from JSON File into Mongo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the data file\n",
    "\n",
    "claraDf = pd.read_json(readLoc, orient='records')\n",
    "if verbose:\n",
    "    display(claraDf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "if verbose:\n",
    "\n",
    "    # count columns and rows\n",
    "    print(\"Number of columns are \" + str(len(claraDf.columns)))\n",
    "    print(\"Number of rows are \" + str(len(claraDf.index)))\n",
    "    print()\n",
    "\n",
    "    # output the shape of the dataframe\n",
    "    print(\"The shape of the data frame is \" + str(claraDf.shape))\n",
    "    print()\n",
    "\n",
    "    # output the column names\n",
    "    print(\"The column names of the data frame are: \")\n",
    "    print(*claraDf, sep='\\n')\n",
    "    print()\n",
    "\n",
    "    # output the column names and datatypes\n",
    "    print(\"The datatypes of the data frame are: \")\n",
    "    print(claraDf.dtypes)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To Do\n",
    "The index need to be replaced with the unique identifier for the student"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through the data frame and build a list\n",
    "# the list will be used for a bulk update of MongoDB\n",
    "\n",
    "# I am having to convert to strings for the intergers as Mongo cannot handle the int64 datatype.\n",
    "# It also cant handle the conversion to int32 at the point of loading the rows, so string is the fall back position\n",
    "\n",
    "# define the list to hold the data\n",
    "clara_row = []\n",
    "\n",
    "# loop through dataframe and create each item in the list\n",
    "for index, row in claraDf.iterrows():\n",
    "    clara_row.insert(\n",
    "        index, {\n",
    "            \"rowIndex\":\n",
    "            index,\n",
    "            \"userId\":\n",
    "            claraDf['userId'].iloc[index],\n",
    "            \"nameId\":\n",
    "            claraDf['nameId'].iloc[index],\n",
    "            \"primaryEmail\":\n",
    "            claraDf['primaryEmail'].iloc[index],\n",
    "            \"journeyId\":\n",
    "            claraDf['journeyId'].iloc[index].astype('str'),\n",
    "            \"journeyTitle\":\n",
    "            claraDf['journeyTitle'].iloc[index],\n",
    "            \"journeyPurpose\":\n",
    "            claraDf['journeyPurpose'].iloc[index],\n",
    "            \"journeyGoal\":\n",
    "            claraDf['journeyGoal'].iloc[index],\n",
    "            \"journeyCreatedAt\":\n",
    "            claraDf['journeyCreatedAt'].iloc[index],\n",
    "            \"claraId\":\n",
    "            claraDf['claraId'].iloc[index].astype('str'),\n",
    "            \"claraResultsJourneyStep\":\n",
    "            claraDf['claraResultsJourneyStep'].iloc[index],\n",
    "            \"claraResultsCreatedAt\":\n",
    "            claraDf['claraResultsCreatedAt'].iloc[index],\n",
    "            \"claraResultCompletedAt\":\n",
    "            claraDf['claraResultCompletedAt'].iloc[index],\n",
    "            \"claraResult1\":\n",
    "            claraDf['claraResult1'].iloc[index],\n",
    "            \"claraResult2\":\n",
    "            claraDf['claraResult2'].iloc[index],\n",
    "            \"claraResult3\":\n",
    "            claraDf['claraResult3'].iloc[index],\n",
    "            \"claraResult4\":\n",
    "            claraDf['claraResult4'].iloc[index],\n",
    "            \"claraResult5\":\n",
    "            claraDf['claraResult5'].iloc[index],\n",
    "            \"claraResult6\":\n",
    "            claraDf['claraResult6'].iloc[index],\n",
    "            \"claraResult7\":\n",
    "            claraDf['claraResult7'].iloc[index],\n",
    "            \"claraResult8\":\n",
    "            claraDf['claraResult8'].iloc[index],\n",
    "            \"insertdate\":\n",
    "            datetime.datetime.utcnow()\n",
    "        })\n",
    "\n",
    "if verbose:\n",
    "    print(clara_row[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bulk update the database\n",
    "\n",
    "raw_data_collection.insert_many(clara_row)\n",
    "\n",
    "if verbose:\n",
    "    print(raw_data_collection.inserted_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only create the indexes onthe first run through\n",
    "if first_run:\n",
    "    # put the restult into a list so it can be looked at later.\n",
    "    result = []\n",
    "\n",
    "    # Create some indexes\n",
    "    result.append(\n",
    "        raw_data_collection.create_index([('index', pymongo.ASCENDING)],\n",
    "                                         unique=False))\n",
    "    result.append(\n",
    "        raw_data_collection.create_index([('userId', pymongo.ASCENDING)],\n",
    "                                         unique=False))\n",
    "    result.append(\n",
    "        raw_data_collection.create_index([('nameId', pymongo.ASCENDING)],\n",
    "                                         unique=False))\n",
    "    result.append(\n",
    "        raw_data_collection.create_index([('primaryEmail', pymongo.ASCENDING)],\n",
    "                                         unique=False))\n",
    "    result.append(\n",
    "        raw_data_collection.create_index([('journeyId', pymongo.ASCENDING)],\n",
    "                                         unique=False))\n",
    "    result.append(\n",
    "        raw_data_collection.create_index(\n",
    "            [('journeyCreatedAt', pymongo.ASCENDING)], unique=False))\n",
    "    result.append(\n",
    "        raw_data_collection.create_index([('claraId', pymongo.ASCENDING)],\n",
    "                                         unique=False))\n",
    "    result.append(\n",
    "        raw_data_collection.create_index(\n",
    "            [('claraResultsCreatedAt', pymongo.ASCENDING)], unique=False))\n",
    "    result.append(\n",
    "        raw_data_collection.create_index(\n",
    "            [('claraResultCompletedAt', pymongo.ASCENDING)], unique=False))\n",
    "    result.append(\n",
    "        raw_data_collection.create_index(\n",
    "            [('claraResultsStep', pymongo.ASCENDING)], unique=False))\n",
    "    result.append(\n",
    "        raw_data_collection.create_index([('insertdate', pymongo.ASCENDING)],\n",
    "                                         unique=False))\n",
    "\n",
    "    if verbose:\n",
    "        print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
