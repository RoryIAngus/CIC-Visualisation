{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code Details\n",
    "Author: Rory Angus<br>\n",
    "Created: 21FEB19<br>\n",
    "Version: 0.1<br>\n",
    "***\n",
    "This code is to test a writing of data to a MongoDB. <br>\n",
    "This is a proof of concept and the data is real. However, it does not bring all of it into Mongo, only the key fields.\n",
    "This uses data that was extracted after the SSO data model was implemented at LE on the platform.\n",
    "The data now is in three parts. The groups and their members, the users linked to the results as well as coaching/coachee relationship.\n",
    "Please note that the results from doing the survey can be more than two per journey and the coaching/coachee relationship is many to many. There is a field called coach on the user but that is from the old version and should not be used.<br>\n",
    "\n",
    "There is also an issue with the data migration onto the new platform which ended up with some users having coaching relationships with UTS students but they are not part of the UTS organisation on the platform. This is no longer possible, so when it happens, this will be patched manually in this code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Package Importing + Variable Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import datetime\n",
    "\n",
    "# mongo stuff\n",
    "import pymongo\n",
    "from pymongo import MongoClient\n",
    "from bson.objectid import ObjectId\n",
    "import bson\n",
    "\n",
    "# json stuff\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the file to read. This needs to be manually updated\n",
    "readLoc = \"~/datasets/CLARA/190328_052400_LE_LivePlatform_UsersCoachRelationship.json\"\n",
    "# if true the code outputs to the notebook a whole of diagnostic data that is helpful when writing but not so much when running it for real\n",
    "verbose = False\n",
    "# first run will truncate the target database and reload it from scratch. Once delta updates have been implmented this needs adjusting\n",
    "first_run = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set display options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# further details found by running:\n",
    "# pd.describe_option('display')\n",
    "# set the values to show all of the columns etc.\n",
    "pd.set_option('display.max_columns', None)  # or 1000\n",
    "pd.set_option('display.max_rows', None)  # or 1000\n",
    "pd.set_option('display.max_colwidth', -1)  # or 199\n",
    "\n",
    "# locals() # show all of the local environments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Connect to Mongo DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the connection to MongoDB\n",
    "# define the location of the Mongo DB Server\n",
    "# in this instance it is a local copy running on the dev machine. This is configurable at this point.\n",
    "client = MongoClient('127.0.0.1', 27017)\n",
    "\n",
    "# define what the database is called.\n",
    "db = client.CLARA\n",
    "\n",
    "# define the collection\n",
    "raw_data_collection = db.raw_data_coach_coachee"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Command to clean the databzse if needed when running this code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete the raw_data_collection - used for testing\n",
    "if first_run:\n",
    "    raw_data_collection.drop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The web framework gets post_id from the URL and passes it as a string\n",
    "def get(post_id):\n",
    "    # Convert from string to ObjectId:\n",
    "    document = client.db.collection.find_one({'_id': ObjectId(post_id)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Place Data from CSV File into Mongo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the data file\n",
    "\n",
    "claraDf = pd.read_json(readLoc, orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of columns are 4\n",
      "Number of rows are 52\n",
      "\n",
      "The shape of the data frame is (52, 4)\n",
      "\n",
      "The column names of the data frame are: \n",
      "coachId\n",
      "dateFrom\n",
      "dateTo\n",
      "learnerId\n",
      "\n",
      "The datatypes of the data frame are: \n",
      "coachId      int64 \n",
      "dateFrom     object\n",
      "dateTo       object\n",
      "learnerId    int64 \n",
      "dtype: object\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if verbose:\n",
    "\n",
    "    # count columns and rows\n",
    "    print(\"Number of columns are \" + str(len(claraDf.columns)))\n",
    "    print(\"Number of rows are \" + str(len(claraDf.index)))\n",
    "    print()\n",
    "\n",
    "    # output the shape of the dataframe\n",
    "    print(\"The shape of the data frame is \" + str(claraDf.shape))\n",
    "    print()\n",
    "\n",
    "    # output the column names\n",
    "    print(\"The column names of the data frame are: \")\n",
    "    print(*claraDf, sep='\\n')\n",
    "    print()\n",
    "\n",
    "    # output the column names and datatypes\n",
    "    print(\"The datatypes of the data frame are: \")\n",
    "    print(claraDf.dtypes)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The datatypes of the data frame are: \n",
      "coachId      object\n",
      "dateFrom     object\n",
      "dateTo       object\n",
      "learnerId    object\n",
      "dtype: object\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# mongo is not able to store integers so convert them to strings\n",
    "\n",
    "claraDf['coachId'] = claraDf['coachId'].astype(str)\n",
    "claraDf['learnerId'] = claraDf['learnerId'].astype(str)\n",
    "\n",
    "# output the column names and datatypes\n",
    "if verbose:\n",
    "    print(\"The datatypes of the data frame are: \")\n",
    "    print(claraDf.dtypes)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'userGroup_index': 5, 'coachId': '3206', 'learnerId': '3103', 'dateFrom': '2018-12-18 22:38:25', 'dateTo': None, 'insertdate': datetime.datetime(2019, 3, 28, 5, 55, 43, 670330)}\n"
     ]
    }
   ],
   "source": [
    "# Loop through the data frame and build a list\n",
    "# the list will be used for a bulk update of MongoDB\n",
    "\n",
    "# define the list to hold the data\n",
    "clara_row = []\n",
    "\n",
    "# loop through dataframe and create each item in the list\n",
    "for index, row in claraDf.iterrows():\n",
    "    clara_row.insert(\n",
    "        index, {\n",
    "            \"userGroup_index\": index,\n",
    "            \"coachId\": claraDf['coachId'].iloc[index],\n",
    "            \"learnerId\": claraDf['learnerId'].iloc[index],\n",
    "            \"dateFrom\": claraDf['dateFrom'].iloc[index],\n",
    "            \"dateTo\": claraDf['dateTo'].iloc[index],\n",
    "            \"insertdate\": datetime.datetime.utcnow()\n",
    "        })\n",
    "\n",
    "if verbose:\n",
    "    print(clara_row[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collection(Database(MongoClient(host=['127.0.0.1:27017'], document_class=dict, tz_aware=False, connect=True), 'CLARA'), 'raw_data_coach_coachee.inserted_ids')\n"
     ]
    }
   ],
   "source": [
    "# bulk update the mongo database\n",
    "\n",
    "raw_data_collection.insert_many(clara_row)\n",
    "\n",
    "if verbose:\n",
    "    print(raw_data_collection.inserted_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['userGroup_index_1', 'coachId_1', 'learnerId_1', 'dateTo_1', 'dateFrom_1']\n"
     ]
    }
   ],
   "source": [
    "# Only create the indexes onthe first run through\n",
    "if first_run:\n",
    "    # put the restult into a list so it can be looked at later.\n",
    "    result = []\n",
    "\n",
    "    # Create some indexes\n",
    "    result.append(\n",
    "        raw_data_collection.create_index(\n",
    "            [('userGroup_index', pymongo.ASCENDING)], unique=False))\n",
    "    result.append(\n",
    "        raw_data_collection.create_index([('coachId', pymongo.ASCENDING)],\n",
    "                                         unique=False))\n",
    "    result.append(\n",
    "        raw_data_collection.create_index([('learnerId', pymongo.ASCENDING)],\n",
    "                                         unique=False))\n",
    "    result.append(\n",
    "        raw_data_collection.create_index([('dateTo', pymongo.ASCENDING)],\n",
    "                                         unique=False))\n",
    "    result.append(\n",
    "        raw_data_collection.create_index([('dateFrom', pymongo.ASCENDING)],\n",
    "                                         unique=False))\n",
    "\n",
    "    if verbose:\n",
    "        print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
