{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code Details\n",
    "Author: Rory Angus<br>\n",
    "Created: 19JAN19<br>\n",
    "Updated: 01APR19 - adjusted to add to the process as well as that the data has changed<br>\n",
    "Version: 0.2<br>\n",
    "***\n",
    "This code loads the results data from Mongo and processes it to ensure that the correct elements are brought together. The end result is a single line that contains a journey, which has the results from the Diagnose and Measure survey.\n",
    "\n",
    "It is important to note that my understanding of the data model has changed since the last code was written. The journey can have many steps and Clara survey results linked to it. In some instances, I have seen up to 8 different Clara results with a single journey. Checking with Shaofu, this is apparently normal, and so I am having to adjust this code to automate the gathering of a single set of data.\n",
    "That is one user -> one journey -> one Clara result for the Diagnose step -> (optional) one Clara result for the Measure step\n",
    "\n",
    "If there are more than two Clara results for step, then a decision needs to be made about which one to keep. I am not sure what that should be. I am guessing the first one for Diagnose and the latest one for Measure. This needs to be verified and certainly, it needs to be flagged in the reporting (new field).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Package Importing + Variable Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "#need to use this otherwise nothing appears in the notebook from the charting point of view\n",
    "matplotlib.use('module://ipykernel.pylab.backend_inline')\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "from itertools import cycle, islice\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from math import pi\n",
    "from math import ceil\n",
    "from math import floor\n",
    "import datetime\n",
    "\n",
    "# mongo stuff\n",
    "import pymongo\n",
    "from pymongo import MongoClient\n",
    "from bson.objectid import ObjectId"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if true the code outputs to the notebook a whole of diagnostic data that is helpful when writing but not so much when running it for real\n",
    "verbose = False\n",
    "# first run will truncate the target database and reload it from scratch. Once delta updates have been implmented this needs adjusting\n",
    "first_run = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set display options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# further details found by running:\n",
    "# pd.describe_option('display')\n",
    "# set the values to show all of the columns etc.\n",
    "pd.set_option('display.max_columns', None)  # or 1000\n",
    "pd.set_option('display.max_rows', None)  # or 1000\n",
    "pd.set_option('display.max_colwidth', -1)  # or 199\n",
    "\n",
    "# locals() # show all of the local environments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Connect to Mongo DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the connection to MongoDB\n",
    "# define the location of the Mongo DB Server\n",
    "# in this instance it is a local copy running on the dev machine. This is configurable at this point.\n",
    "client = MongoClient('127.0.0.1', 27017)\n",
    "\n",
    "# define what the database is called.\n",
    "db = client.CLARA\n",
    "\n",
    "# define the collection\n",
    "#raw_data_collection = db.raw_data\n",
    "raw_data_collection = db.raw_data_user_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Data \n",
    "This uses a variable that is defined above and puts it into a filter based on the student index. <br>\n",
    "This needs to be replaced with the student ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query the data from the database using a filter\n",
    "query_field = \"userEmail\"\n",
    "\n",
    "# return results sorted\n",
    "cursor = raw_data_collection.find().sort([(query_field, 1)])\n",
    "\n",
    "# put the results into a dataframe\n",
    "df = pd.DataFrame(list(cursor))\n",
    "\n",
    "if verbose:\n",
    "    print(df.shape)\n",
    "    display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if verbose:\n",
    "\n",
    "    # count columns and rows\n",
    "    print(\"Number of columns are \" + str(len(df.columns)))\n",
    "    print(\"Number of rows are \" + str(len(df.index)))\n",
    "    print()\n",
    "\n",
    "    # output the shape of the dataframe\n",
    "    print(\"The shape of the data frame is \" + str(df.shape))\n",
    "    print()\n",
    "\n",
    "    # output the column names\n",
    "    print(\"The column names of the data frame are: \")\n",
    "    print(*df, sep='\\n')\n",
    "    print()\n",
    "\n",
    "    # output the column names and datatypes\n",
    "    print(\"The datatypes of the data frame are: \")\n",
    "    print(df.dtypes)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove the fields that we don't currently need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the unique users from data frame. This is what we will interate through\n",
    "userId = df['userId'].unique()\n",
    "\n",
    "if verbose:\n",
    "    display(userId.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calc Number of Surveys & Type per Journey\n",
    "\n",
    "This goes through each user and looks at each journey then works out how many surveys in total for each journey. There can be 0, 1 or 2 to make it a valid data set. If there is more then there is an issue that will need to be manually investigated and corrected. \n",
    "\n",
    "It takes this further and works out how many diagnose and measure surveys per journey. This is to ensure that each journey has at only one of each type and that the logic takes into account that a journey with two surveys may not be correct if they are both diagnostic ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# set the counting variable up\n",
    "userPos = 0\n",
    "\n",
    "while userPos <= len(userId) - 1:\n",
    "    # assign this users data to a temp dataframe for working with\n",
    "    tudf = df[df['userId'] == userId[userPos]]\n",
    "\n",
    "    # count number of rows of data returned for each user\n",
    "    # this is a new feature that can be used to see how many surveys this users has done\n",
    "    df.loc[df['userId'] == userId[userPos], 'numTotalClaraSurveys'] = len(tudf)\n",
    "\n",
    "    # get the list of unique journey Id's for this user only\n",
    "    journeyId = tudf['journeyId'].unique()\n",
    "\n",
    "    # loop through the journeys for each user\n",
    "    # remember that each journey can have one or more rows of data.\n",
    "    journeyPos = 0\n",
    "    while journeyPos <= len(journeyId) - 1:\n",
    "        # assign this users data for a single journey to a temp dataframe for working with\n",
    "        tjdf = df[df['journeyId'] == journeyId[journeyPos]]\n",
    "        # count number of rows of data returned for each user per journey\n",
    "        # this is a new feature that can be used to see how many surveys this users has done for each journey\n",
    "        df.loc[((df['userId'] == userId[userPos]) &\n",
    "                (df['journeyId'] == journeyId[journeyPos])\n",
    "                ), 'numTotalClaraJourneySurveys'] = len(tjdf)\n",
    "        # work out how many diagnose surveys per journey\n",
    "        df.loc[((df['userId'] == userId[userPos]) &\n",
    "                (df['journeyId'] == journeyId[journeyPos]) &\n",
    "                (df['claraResultsJourneyStep'] == 'diagnose')\n",
    "                ), 'numDiagnoseSurveysPerJourney'] = len(\n",
    "                    tjdf[tjdf['claraResultsJourneyStep'] == 'diagnose'])\n",
    "        # work out how many measure surveys per journey\n",
    "        df.loc[((df['userId'] == userId[userPos]) &\n",
    "                (df['journeyId'] == journeyId[journeyPos]) &\n",
    "                (df['claraResultsJourneyStep'] == 'measure')\n",
    "                ), 'numMeasureSurveysPerJourney'] = len(\n",
    "                    tjdf[tjdf['claraResultsJourneyStep'] == 'measure'])\n",
    "\n",
    "        # increment journey by 1\n",
    "        journeyPos += 1\n",
    "\n",
    "    # increment user by 1\n",
    "    userPos += 1\n",
    "#df\n",
    "\n",
    "# d167cf61-44a0-442c-9105-2d73b7d1decc is a good test case"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiple Surveys Error Reporting\n",
    "This section will display any rows that need to be manually managed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look for data that have more than type of survey (diagnose or measure) per journey\n",
    "dfError = df.loc[(\n",
    "    (df['numTotalClaraJourneySurveys'] >= 3)\n",
    "    &  # if there are three surveys, at least one is doubled up and needs investigating\n",
    "    ((df['numDiagnoseSurveysPerJourney'] >= 2)\n",
    "     |  ## use or because it may be either step that has more than the one\n",
    "     (df['numMeasureSurveysPerJourney'] >= 2)))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(dfError) > 0:\n",
    "    print(\n",
    "        \"There is some data that you need to look at to work out which records to keep. The data in question is stored in the \"\n",
    "        \"data frame called dfError and is presented here for ease.\")\n",
    "    display(dfError)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build new data frame containing linked surveys\n",
    "This section takes the clean data and builds the data structure to hold the information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finds all of the diagnose surveys that have a corresponding measure survey\n",
    "# this also assumes that there is only one of each\n",
    "# the ones with more need to be handled with exception code\n",
    "dfDiagnose = df.loc[(\n",
    "    (df['numTotalClaraJourneySurveys'] == 2) &\n",
    "    (df['numDiagnoseSurveysPerJourney'] == 1)) | (\n",
    "        (df['numTotalClaraJourneySurveys'] == 1\n",
    "         ) &  # bring in all the surveys that only have a diagnose step\n",
    "        (df['claraResultsJourneyStep'] == 'diagnose'))].copy()\n",
    "\n",
    "dfMeasure = df.loc[((df['numTotalClaraJourneySurveys'] == 2) &\n",
    "                    (df['numMeasureSurveysPerJourney'] == 1))].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the uneeded columns from the diagnose as they will be merged back into the dataframe\n",
    "\n",
    "dfDiagnose.drop(['numMeasureSurveysPerJourney'],\n",
    "                inplace=True,\n",
    "                axis=1,\n",
    "                errors='ignore')\n",
    "# drop the uneeded columns from the measure as they will be merged back into the dataframe\n",
    "dfMeasure.drop([\n",
    "    'insertdate', 'journeyCreatedAt', 'journeyGoal', 'journeyPurpose',\n",
    "    'journeyTitle', 'userClientUserId', 'userCoachId', 'userEmail',\n",
    "    'numTotalClaraSurveys', 'numTotalClaraJourneySurveys',\n",
    "    'numDiagnoseSurveysPerJourney', '_id', 'userExtraData',\n",
    "    'userLanguagePreference', 'rowIndex', 'userAvatarSupplied',\n",
    "    'userDeclaraLinked', 'userDeletedAt', 'userStatus', 'nameId',\n",
    "    'primaryEmail'\n",
    "],\n",
    "               inplace=True,\n",
    "               axis=1,\n",
    "               errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename column headings for the measure survey\n",
    "\n",
    "colNames = [\n",
    "    'measure_ClaraId', 'measure_ClaraResult1', 'measure_ClaraResult2',\n",
    "    'measure_ClaraResult3', 'measure_ClaraResult4', 'measure_ClaraResult5',\n",
    "    'measure_ClaraResult6', 'measure_ClaraResult7', 'measure_ClaraResult8',\n",
    "    'measure_ClaraResultCompletedAt', 'measure_ClaraResultsCreatedAt',\n",
    "    'measure_ClaraResultsJourneyStep', 'journeyId', 'userId',\n",
    "    'numMeasureSurveysPerJourney'\n",
    "]\n",
    "\n",
    "dfMeasure.columns = colNames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if verbose:\n",
    "    dfDiagnose.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename column headings for the diagnose survey\n",
    "\n",
    "colNames = [\n",
    "    '_id', 'diagnose_ClaraId', 'diagnose_ClaraResult1',\n",
    "    'diagnose_ClaraResult2', 'diagnose_ClaraResult3', 'diagnose_ClaraResult4',\n",
    "    'diagnose_ClaraResult5', 'diagnose_ClaraResult6', 'diagnose_ClaraResult7',\n",
    "    'diagnose_ClaraResult8', 'diagnose_ClaraResultCompletedAt',\n",
    "    'diagnose_ClaraResultsCreatedAt', 'claraResultsJourneyStep', 'insertdate',\n",
    "    'journeyCreatedAt', 'journeyGoal', 'journeyId', 'journeyPurpose',\n",
    "    'journeyTitle', 'nameId', 'primaryEmail', 'rowIndex', 'userId',\n",
    "    'numTotalClaraSurveys', 'numTotalClaraJourneySurveys',\n",
    "    'numDiagnoseSurveysPerJourney'\n",
    "]\n",
    "\n",
    "dfDiagnose.columns = colNames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# merge the two datadrames diagnose and measure to end up with the data having the structure of 1 row per journey\n",
    "# with the second survey completed if applicable\n",
    "dfResult = pd.merge(\n",
    "    dfDiagnose,\n",
    "    dfMeasure,\n",
    "    left_on=['journeyId', 'userId'],\n",
    "    right_on=['journeyId', 'userId'],\n",
    "    how='outer')\n",
    "\n",
    "# reset index - just in case => makes it unique\n",
    "dfResult = dfResult.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if verbose:\n",
    "    dfResult.shape\n",
    "    print(*dfResult, sep='\\n')\n",
    "    display(dfResult)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write to Mongo the file file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To Do\n",
    "The index need to be replaced with the unique identifier for the student"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through the data frame and build a list\n",
    "# the list will be used for a bulk update of MongoDB\n",
    "\n",
    "# I am having to convert to strings for the intergers as Mongo cannot handle the int64 datatype.\n",
    "# It also cant handle the conversion to int32 at the point of loading the rows, so string is the fall back position\n",
    "\n",
    "# define the list to hold the data\n",
    "clara_row = []\n",
    "\n",
    "# loop through dataframe and create each item in the list\n",
    "for index, row in dfResult.iterrows():\n",
    "    clara_row.insert(\n",
    "        index, {\n",
    "            \"rowIndex\":\n",
    "            index,\n",
    "            \"journeyId\":\n",
    "            dfResult['journeyId'].iloc[index],\n",
    "            \"journeyTitle\":\n",
    "            dfResult['journeyTitle'].iloc[index],\n",
    "            \"journeyPurpose\":\n",
    "            dfResult['journeyPurpose'].iloc[index],\n",
    "            \"journeyGoal\":\n",
    "            dfResult['journeyGoal'].iloc[index],\n",
    "            \"journeyCreatedAt\":\n",
    "            dfResult['journeyCreatedAt'].iloc[index],\n",
    "            \"diagnose_ClaraId\":\n",
    "            dfResult['diagnose_ClaraId'].iloc[index],\n",
    "            \"claraResultsJourneyStep\":\n",
    "            dfResult['claraResultsJourneyStep'].iloc[index],\n",
    "            \"diagnose_ClaraResultsCreatedAt\":\n",
    "            dfResult['diagnose_ClaraResultsCreatedAt'].iloc[index],\n",
    "            \"diagnose_ClaraResultCompletedAt\":\n",
    "            dfResult['diagnose_ClaraResultCompletedAt'].iloc[index],\n",
    "            \"diagnose_ClaraResult1\":\n",
    "            dfResult['diagnose_ClaraResult1'].iloc[index],\n",
    "            \"diagnose_ClaraResult2\":\n",
    "            dfResult['diagnose_ClaraResult2'].iloc[index],\n",
    "            \"diagnose_ClaraResult3\":\n",
    "            dfResult['diagnose_ClaraResult3'].iloc[index],\n",
    "            \"diagnose_ClaraResult4\":\n",
    "            dfResult['diagnose_ClaraResult4'].iloc[index],\n",
    "            \"diagnose_ClaraResult5\":\n",
    "            dfResult['diagnose_ClaraResult5'].iloc[index],\n",
    "            \"diagnose_ClaraResult6\":\n",
    "            dfResult['diagnose_ClaraResult6'].iloc[index],\n",
    "            \"diagnose_ClaraResult7\":\n",
    "            dfResult['diagnose_ClaraResult7'].iloc[index],\n",
    "            \"diagnose_ClaraResult8\":\n",
    "            dfResult['diagnose_ClaraResult8'].iloc[index],\n",
    "            \"measure_ClaraId\":\n",
    "            dfResult['measure_ClaraId'].iloc[index],\n",
    "            \"measure_ClaraResultsJourneyStep\":\n",
    "            dfResult['measure_ClaraResultsJourneyStep'].iloc[index],\n",
    "            \"measure_ClaraResultsCreatedAt\":\n",
    "            dfResult['measure_ClaraResultsCreatedAt'].iloc[index],\n",
    "            \"measure_ClaraResultCompletedAt\":\n",
    "            dfResult['measure_ClaraResultCompletedAt'].iloc[index],\n",
    "            \"measure_ClaraResult1\":\n",
    "            dfResult['measure_ClaraResult1'].iloc[index],\n",
    "            \"measure_ClaraResult2\":\n",
    "            dfResult['measure_ClaraResult2'].iloc[index],\n",
    "            \"measure_ClaraResult3\":\n",
    "            dfResult['measure_ClaraResult3'].iloc[index],\n",
    "            \"measure_ClaraResult4\":\n",
    "            dfResult['measure_ClaraResult4'].iloc[index],\n",
    "            \"measure_ClaraResult5\":\n",
    "            dfResult['measure_ClaraResult5'].iloc[index],\n",
    "            \"measure_ClaraResult6\":\n",
    "            dfResult['measure_ClaraResult6'].iloc[index],\n",
    "            \"measure_ClaraResult7\":\n",
    "            dfResult['measure_ClaraResult7'].iloc[index],\n",
    "            \"measure_ClaraResult8\":\n",
    "            dfResult['measure_ClaraResult8'].iloc[index],\n",
    "            \"numTotalClaraSurveys\":\n",
    "            dfResult['numTotalClaraSurveys'].iloc[index],\n",
    "            \"numTotalClaraJourneySurveys\":\n",
    "            dfResult['numTotalClaraJourneySurveys'].iloc[index],\n",
    "            \"userNameId\":\n",
    "            dfResult['nameId'].iloc[index],\n",
    "            \"userPrimaryEmail\":\n",
    "            dfResult['primaryEmail'].iloc[index],\n",
    "            \"userId\":\n",
    "            dfResult['userId'].iloc[index],\n",
    "            \"insertdate\":\n",
    "            datetime.datetime.utcnow()\n",
    "        })\n",
    "\n",
    "if verbose:\n",
    "    print(clara_row[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Connect to Mongo DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the connection to MongoDB\n",
    "# define the location of the Mongo DB Server\n",
    "# in this instance it is a local copy running on the dev machine. This is configurable at this point.\n",
    "client = MongoClient('127.0.0.1', 27017)\n",
    "\n",
    "# define what the database is called.\n",
    "db = client.CLARA\n",
    "\n",
    "# define the collection\n",
    "# This is the collection that the data will be saved to. This is the processed data and used later for the analysis\n",
    "raw_data_collection = db.raw_data_combined_user_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Command to clean the database if needed when running this code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete the raw_data_collection - used for testing\n",
    "if first_run:\n",
    "    raw_data_collection.drop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Post the data to the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bulk update the database\n",
    "\n",
    "raw_data_collection.insert_many(clara_row)\n",
    "\n",
    "if verbose:\n",
    "    print(raw_data_collection.inserted_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create some indexes\n",
    "result = []\n",
    "\n",
    "result.append(\n",
    "    raw_data_collection.create_index([('rowIndex', pymongo.ASCENDING)],\n",
    "                                     unique=True))\n",
    "result.append(\n",
    "    raw_data_collection.create_index([('userId', pymongo.ASCENDING)],\n",
    "                                     unique=False))\n",
    "result.append(\n",
    "    raw_data_collection.create_index([('userPrimaryEmail', pymongo.ASCENDING)],\n",
    "                                     unique=False))\n",
    "result.append(\n",
    "    raw_data_collection.create_index([('userClientUserId', pymongo.ASCENDING)],\n",
    "                                     unique=False))\n",
    "result.append(\n",
    "    raw_data_collection.create_index([('userNameId', pymongo.ASCENDING)],\n",
    "                                     unique=False))\n",
    "result.append(\n",
    "    raw_data_collection.create_index([('journeyId', pymongo.ASCENDING)],\n",
    "                                     unique=False))\n",
    "result.append(\n",
    "    raw_data_collection.create_index([('journeyCreatedAt', pymongo.ASCENDING)],\n",
    "                                     unique=False))\n",
    "result.append(\n",
    "    raw_data_collection.create_index([('diagnose_ClaraId', pymongo.ASCENDING)],\n",
    "                                     unique=False))\n",
    "result.append(\n",
    "    raw_data_collection.create_index(\n",
    "        [('diagnose_ClaraResultsCreatedAt', pymongo.ASCENDING)], unique=False))\n",
    "result.append(\n",
    "    raw_data_collection.create_index(\n",
    "        [('diagnose_ClaraResultCompletedAt', pymongo.ASCENDING)],\n",
    "        unique=False))\n",
    "result.append(\n",
    "    raw_data_collection.create_index(\n",
    "        [('diagnose_ClaraResultsStep', pymongo.ASCENDING)], unique=False))\n",
    "result.append(\n",
    "    raw_data_collection.create_index([('measure_ClaraId', pymongo.ASCENDING)],\n",
    "                                     unique=False))\n",
    "result.append(\n",
    "    raw_data_collection.create_index(\n",
    "        [('measure_ClaraResultsCreatedAt', pymongo.ASCENDING)], unique=False))\n",
    "result.append(\n",
    "    raw_data_collection.create_index(\n",
    "        [('measure_ClaraResultCompletedAt', pymongo.ASCENDING)], unique=False))\n",
    "result.append(\n",
    "    raw_data_collection.create_index(\n",
    "        [('measure_ClaraResultsStep', pymongo.ASCENDING)], unique=False))\n",
    "result.append(\n",
    "    raw_data_collection.create_index([('insertdate', pymongo.ASCENDING)],\n",
    "                                     unique=False))\n",
    "\n",
    "if verbose:\n",
    "    print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
